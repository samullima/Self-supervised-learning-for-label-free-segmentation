{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-04T20:10:02.206879Z",
     "iopub.status.busy": "2025-12-04T20:10:02.206582Z",
     "iopub.status.idle": "2025-12-04T20:10:02.412655Z",
     "shell.execute_reply": "2025-12-04T20:10:02.411859Z",
     "shell.execute_reply.started": "2025-12-04T20:10:02.206849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.io import decode_image\n",
    "from torchvision.io.image import ImageReadMode\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from skimage import morphology, measure\n",
    "\n",
    "DEVICE = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o caminho do dataset de input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:10:02.413761Z",
     "iopub.status.busy": "2025-12-04T20:10:02.413516Z",
     "iopub.status.idle": "2025-12-04T20:10:02.418634Z",
     "shell.execute_reply": "2025-12-04T20:10:02.417759Z",
     "shell.execute_reply.started": "2025-12-04T20:10:02.413735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#### SE FOR RODAR NO KAGGLE\n",
    "# INPUT_DIR = \"/kaggle/input/chest-xray-pneumonia/chest_xray/\"\n",
    "#### SE QUISER RODAR LOCAL OU NO COLAB\n",
    "INPUT_DIR = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "INPUT_DIR += \"/chest_xray/\"\n",
    "# OUTPUT_DIR = \"/kaggle/working/weak_masks\"\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição das funções que geram as weak labels e que calculam o QC (Quality Control)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:10:22.761950Z",
     "iopub.status.busy": "2025-12-04T20:10:22.761385Z",
     "iopub.status.idle": "2025-12-04T20:10:22.772302Z",
     "shell.execute_reply": "2025-12-04T20:10:22.771609Z",
     "shell.execute_reply.started": "2025-12-04T20:10:22.761925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_weak_mask_cxr(img_path):\n",
    "    # Carrega a imagem e redimenciona\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    h, w = img.shape\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    # \"Estoura\" pixels extremos para que não entrem na máscara\n",
    "    img[img < 50] = 255 \n",
    "    img[img > 180] = 255\n",
    "    \n",
    "    # Equalização + suavização\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    I = clahe.apply(img)\n",
    "    I = cv2.GaussianBlur(I, (7,7), 0)\n",
    "    \n",
    "    for ang in np.arange(0, 151, 30):\n",
    "        se = np.zeros((15, 15), np.uint8)\n",
    "        cv2.ellipse(se, (15//2, 15//2), (15//2, 1), ang, 0, 360, 1, -1)\n",
    "        I_supp = cv2.morphologyEx(I, cv2.MORPH_OPEN, se)\n",
    "        I = cv2.min(I, I_supp)\n",
    "        \n",
    "    # Inverte para que opacidades fiquem claras\n",
    "    I_inv = cv2.normalize(255 - I, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Filtro bilateral\n",
    "    I_inv_bilateral = cv2.bilateralFilter(I_inv.astype(np.uint8), d=-1, sigmaColor=0.25*255, sigmaSpace=15)\n",
    "\n",
    "    # Aplica um treshold simples\n",
    "    _, bw = cv2.threshold(I_inv_bilateral, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Limpa regiões fora dos pulmões\n",
    "    # remove um pequeno pedaço do topo e das laterais que não incluem o pulmão (geralmente)\n",
    "    bw[:40, :], bw[:, -70:], bw[:, :70] = 0,0, 0\n",
    "    \n",
    "    # Morfologia para suavizar\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
    "    bw = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel)\n",
    "    bw = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Mantém regiões internas\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(bw)\n",
    "    mask_out = np.zeros_like(bw)\n",
    "    \n",
    "    for i in range(1, num_labels):\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        x,y = stats[i, cv2.CC_STAT_LEFT], stats[i, cv2.CC_STAT_TOP]\n",
    "        wc,hc = stats[i, cv2.CC_STAT_WIDTH], stats[i, cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "        # Descarta regiões no topo e muito pequenas\n",
    "        if area > 500 and y > 39:\n",
    "            mask_out[labels == i] = 255\n",
    "\n",
    "    # Remove objetos pequenos (geralmente ombro ou parte da silhueta lateral)\n",
    "    mask_out = morphology.remove_small_objects(mask_out.astype(bool), min_size=5000)\n",
    "    \n",
    "    # Volta ao tamanho original\n",
    "    mask_out = mask_out.astype(np.uint8)\n",
    "    mask_out = cv2.resize(mask_out, (w, h))\n",
    "    \n",
    "    return torch.from_numpy(mask_out).unsqueeze(0).float()\n",
    "\n",
    "# Função QC\n",
    "def qc_score(mask, min_area=0.04, max_area=0.3, min_ecc=0.4, max_ecc=0.98, max_aspect=0.35, num_obj=2):\n",
    "    props = measure.regionprops(measure.label(mask[0]))\n",
    "    # Apenas os 2 maiores objetos (idealmente apenas pulmões)\n",
    "    props = sorted(props, key=lambda x: x.area, reverse=True)[:2]\n",
    "\n",
    "    H, W = mask[0].shape\n",
    "\n",
    "    scores = 0\n",
    "\n",
    "    try:\n",
    "        biggest_area = props[0].area\n",
    "    except:\n",
    "        print(f\"Mascara problemática, Nº de objetos nela: {len(props)}\")\n",
    "        return 0\n",
    "\n",
    "    for p in props:\n",
    "        lung_scores = list()\n",
    "        # Área relativa\n",
    "        area_frac = p.area / (H * W)\n",
    "        if area_frac < min_area:\n",
    "            lung_scores.append(area_frac / min_area)\n",
    "        elif area_frac > max_area:\n",
    "            lung_scores.append(max_area / area_frac)\n",
    "        else:\n",
    "            lung_scores.append(1.0)\n",
    "\n",
    "        # Eccentricidade\n",
    "        ecc = p.eccentricity\n",
    "        if ecc < min_ecc:\n",
    "            lung_scores.append(ecc / min_ecc)\n",
    "        elif ecc > max_ecc:\n",
    "            lung_scores.append(max_ecc / ecc)\n",
    "        else:\n",
    "            lung_scores.append(1.0)\n",
    "\n",
    "        # Solidity\n",
    "        lung_scores.append(p.solidity)\n",
    "\n",
    "        # Extent\n",
    "        lung_scores.append(p.extent)\n",
    "\n",
    "        # Aspect ratio\n",
    "        minr, minc, maxr, maxc = p.bbox\n",
    "        bbox_h = maxr - minr\n",
    "        bbox_w = maxc - minc\n",
    "        aspect = max(bbox_h / (bbox_w + 1e-9), bbox_w / (bbox_h + 1e-9))\n",
    "        if aspect > max_aspect:\n",
    "            lung_scores.append(max_aspect / aspect)\n",
    "        else:\n",
    "            lung_scores.append(1.0)\n",
    "\n",
    "        # Nº de objetos\n",
    "        n_obj = len(props)\n",
    "        if n_obj > num_obj:\n",
    "            lung_scores.append(1 / n_obj)\n",
    "        else:\n",
    "            lung_scores.append(n_obj / num_obj)\n",
    "       \n",
    "        # Soma o score do pulmão ao score final ponderado pela diferença de tamanho entre pulmões \n",
    "        scores += np.mean(lung_scores) * (p.area / biggest_area)\n",
    "\n",
    "    return scores / 2 # Média dos pulmões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfSegCXRDataset(Dataset):\n",
    "    def __init__(self, dataset_path=INPUT_DIR, image_size=None, device=DEVICE):\n",
    "\n",
    "        self._path_data = dataset_path\n",
    "\n",
    "        self.data = glob(os.path.join(self._path_data, \"**\", \"**\", \"*.jpeg\"), recursive=True)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        if image_size:\n",
    "            self.resize_image = v2.Resize(size=image_size, interpolation=v2.InterpolationMode.BILINEAR, antialias=True)\n",
    "            self.resize_mask = v2.Resize(size=image_size, interpolation=v2.InterpolationMode.NEAREST)\n",
    "        else:\n",
    "            self.resize_image = lambda x: x\n",
    "            self.resize_mask = lambda x: x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.data[index]\n",
    "\n",
    "        image = decode_image(image_path, mode=ImageReadMode.GRAY).to(self.device)\n",
    "        mask = generate_weak_mask_cxr(image_path)\n",
    "\n",
    "        qc = qc_score(mask)\n",
    "\n",
    "        image = self.resize_image(image)\n",
    "        mask = self.resize_mask(mask)\n",
    "\n",
    "        return image, mask, qc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pequeno teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:28:18.652746Z",
     "iopub.status.busy": "2025-12-04T20:28:18.652056Z",
     "iopub.status.idle": "2025-12-04T20:28:19.214697Z",
     "shell.execute_reply": "2025-12-04T20:28:19.213866Z",
     "shell.execute_reply.started": "2025-12-04T20:28:18.652718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds = SelfSegCXRDataset(image_size=(512, 512))\n",
    "\n",
    "for i in range(5):\n",
    "    img, mask, qc = ds[i]\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Imagem Original\")\n",
    "    plt.imshow(img.cpu()[0], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Weak Label Gerada\")\n",
    "    plt.imshow(mask.cpu()[0], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    print(f\"QC_{i+1} = {qc}\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSoftDiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(WeightedSoftDiceLoss, self).__init__()\n",
    "        self._smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets, weights=None):\n",
    "        \"\"\"\n",
    "        preds: tensor [B,1,H,W] com probabilidades\n",
    "        targets: tensor [B,1,H,W] com ground truth binário\n",
    "        weights: tensor [B] com pesos por amostra\n",
    "        \"\"\"\n",
    "        B = preds.shape[0]\n",
    "        losses = []\n",
    "        for i in range(B):\n",
    "            p = preds[i].view(-1)\n",
    "            g = targets[i].view(-1)\n",
    "\n",
    "            intersection = torch.sum(p * g)\n",
    "            dice = (2. * intersection + self._smooth) / (torch.sum(p) + torch.sum(g) + self._smooth)\n",
    "            loss = 1 - dice\n",
    "\n",
    "            if weights is not None:\n",
    "                loss = loss * weights[i]\n",
    "\n",
    "            losses.append(loss)\n",
    "\n",
    "        losses = torch.stack(losses)\n",
    "\n",
    "        if weights is not None:\n",
    "            return torch.sum(losses) / (torch.sum(weights) + self._smooth)\n",
    "        else:\n",
    "            return torch.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definições do modelo (primeiro da pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:38:32.548868Z",
     "iopub.status.busy": "2025-12-04T20:38:32.548143Z",
     "iopub.status.idle": "2025-12-04T20:38:46.688832Z",
     "shell.execute_reply": "2025-12-04T20:38:46.688045Z",
     "shell.execute_reply.started": "2025-12-04T20:38:32.548835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    "    activation=\"sigmoid\"\n",
    ")\n",
    "\n",
    "loss = WeightedSoftDiceLoss()\n",
    "\n",
    "dataset = SelfSegCXRDataset(image_size=(512,512))\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total = 0\n",
    "\n",
    "    print(f\"Iniciando época {epoch + 1}\")\n",
    "    for i, (imgs, masks, qc) in enumerate(train_loader):\n",
    "        imgs = imgs.to(DEVICE).float()\n",
    "        masks = masks.to(DEVICE)\n",
    "\n",
    "        preds = model(imgs)\n",
    "        loss_value = loss(preds, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss_value.item()\n",
    "        \n",
    "        for k in range(4):\n",
    "            print(f\"QC_{k+1} da weak_label inicial = {qc[k]}\")\n",
    "\n",
    "            plt.figure(figsize=(9,3))\n",
    "\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.title(\"Imagem Original\")\n",
    "            plt.imshow(imgs[k].cpu()[0], cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.title(\"Weak Label inicial\")\n",
    "            plt.imshow(masks[k].cpu()[0], cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            plt.subplot(1,3,3)\n",
    "            plt.title(\"Weak Label Gerada\")\n",
    "            plt.imshow(preds[k].detach().cpu()[0], cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
