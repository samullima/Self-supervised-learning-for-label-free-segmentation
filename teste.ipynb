{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-04T20:10:02.206879Z",
     "iopub.status.busy": "2025-12-04T20:10:02.206582Z",
     "iopub.status.idle": "2025-12-04T20:10:02.412655Z",
     "shell.execute_reply": "2025-12-04T20:10:02.411859Z",
     "shell.execute_reply.started": "2025-12-04T20:10:02.206849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.io import decode_image\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "DEVICE = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:10:02.413761Z",
     "iopub.status.busy": "2025-12-04T20:10:02.413516Z",
     "iopub.status.idle": "2025-12-04T20:10:02.418634Z",
     "shell.execute_reply": "2025-12-04T20:10:02.417759Z",
     "shell.execute_reply.started": "2025-12-04T20:10:02.413735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = \"/kaggle/input/chest-xray-pneumonia/chest_xray/test/NORMAL\"\n",
    "OUTPUT_DIR = \"/kaggle/working/weak_masks\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:10:22.761950Z",
     "iopub.status.busy": "2025-12-04T20:10:22.761385Z",
     "iopub.status.idle": "2025-12-04T20:10:22.772302Z",
     "shell.execute_reply": "2025-12-04T20:10:22.771609Z",
     "shell.execute_reply.started": "2025-12-04T20:10:22.761925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_weak_mask_cxr(img_path):\n",
    "    # 1. carregar\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    h, w = img.shape\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    \n",
    "    img[img < 50] = 255 \n",
    "    img[img > 180] = 255\n",
    "    \n",
    "    # 2. equalização + suavização\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    I = clahe.apply(img)\n",
    "    I = cv2.GaussianBlur(I, (7,7), 0)\n",
    "    \n",
    "    for ang in np.arange(0, 151, 30):\n",
    "        se = np.zeros((15, 15), np.uint8)\n",
    "        cv2.ellipse(se, (15//2, 15//2), (15//2, 1), ang, 0, 360, 1, -1)\n",
    "        I_supp = cv2.morphologyEx(I, cv2.MORPH_OPEN, se)\n",
    "        I = cv2.min(I, I_supp)\n",
    "        \n",
    "    # 3. inverter para que opacidades fiquem claras\n",
    "    I_inv = cv2.normalize(255 - I, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # 4. opções de threshold (escolha uma)\n",
    "    _, bw = cv2.threshold(I_inv, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 5. limpar regiões fora dos pulmões\n",
    "    # remove um pequeno pedaço do topo e das laterais que não incluem o pulmão (geralmente)\n",
    "    bw[:40, :], bw[:, -70:], bw[:, :70] = 0,0, 0\n",
    "    \n",
    "    # 6. morfologia para suavizar\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
    "    bw = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel)\n",
    "    bw = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # 7. manter regiões internas\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(bw)\n",
    "    mask_out = np.zeros_like(bw)\n",
    "    \n",
    "    for i in range(1, num_labels):\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        x,y = stats[i, cv2.CC_STAT_LEFT], stats[i, cv2.CC_STAT_TOP]\n",
    "        wc,hc = stats[i, cv2.CC_STAT_WIDTH], stats[i, cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "        # descarta regiões no topo e muito pequenas\n",
    "        if area > 500 and y > 39:\n",
    "            mask_out[labels == i] = 255\n",
    "    \n",
    "    # 8. voltar ao tamanho original\n",
    "    mask_out = cv2.resize(mask_out, (w, h))\n",
    "    return (mask_out > 0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfSegDataset(Dataset):\n",
    "    def __init__(self, dataset_path=INPUT_DIR, image_size=None, device=DEVICE):\n",
    "\n",
    "        self._path_data = dataset_path\n",
    "\n",
    "        self.data = glob(os.path.join(self._path_data, \"**\", \"*.jpeg\"), recursive=True)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        if image_size:\n",
    "            self.resize_image = v2.Resize(size=image_size, interpolation=v2.InterpolationMode.BILINEAR, antialias=True)\n",
    "            self.resize_mask = v2.Resize(size=image_size, interpolation=v2.InterpolationMode.NEAREST)\n",
    "        else:\n",
    "            self.resize_image = lambda x: x\n",
    "            self.resize_mask = lambda x: x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.data[index]\n",
    "\n",
    "        image = decode_image(image_path).to(self.device)\n",
    "        mask = generate_weak_mask_cxr(image_path)\n",
    "\n",
    "        image = self.resize_image(image)\n",
    "        mask = self.resize_mask(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def orig_image(self, index):\n",
    "        image_path = self.data[index]\n",
    "        return decode_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:10:37.005024Z",
     "iopub.status.busy": "2025-12-04T20:10:37.004424Z",
     "iopub.status.idle": "2025-12-04T20:10:46.272311Z",
     "shell.execute_reply": "2025-12-04T20:10:46.271561Z",
     "shell.execute_reply.started": "2025-12-04T20:10:37.004997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:09<00:00, 25.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Gera máscaras binárias de 0 ou 255.\n",
    "# for filename in tqdm(os.listdir(INPUT_DIR)):\n",
    "#     # if filename.lower().endswith(\".png\":\n",
    "#         img_path = os.path.join(INPUT_DIR, filename)\n",
    "#         mask = generate_weak_mask_cxr(img_path)\n",
    "#         cv2.imwrite(os.path.join(OUTPUT_DIR, filename.rsplit(\".\",1)[0] + \".png\"), (mask*255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:28:18.652746Z",
     "iopub.status.busy": "2025-12-04T20:28:18.652056Z",
     "iopub.status.idle": "2025-12-04T20:28:19.214697Z",
     "shell.execute_reply": "2025-12-04T20:28:19.213866Z",
     "shell.execute_reply.started": "2025-12-04T20:28:18.652718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds = SelfSegDataset(image_size=(512, 512))\n",
    "\n",
    "for i in range(5):\n",
    "    img, mask = ds[i]\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Imagem Original\")\n",
    "    plt.imshow(img.cpu()[0], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Weak Label Gerada\")\n",
    "    plt.imshow(mask.cpu()[0], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando UNet com ativação Sigmóide para treinar as Weak Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:38:32.548868Z",
     "iopub.status.busy": "2025-12-04T20:38:32.548143Z",
     "iopub.status.idle": "2025-12-04T20:38:46.688832Z",
     "shell.execute_reply": "2025-12-04T20:38:46.688045Z",
     "shell.execute_reply.started": "2025-12-04T20:38:32.548835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    "    activation=\"sigmoid\"\n",
    ")\n",
    "\n",
    "loss = smp.losses.DiceLoss(mode=\"binary\")\n",
    "\n",
    "dataset = SelfSegDataset(image_size=(512,512))\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total = 0\n",
    "\n",
    "    for i, (imgs, masks) in enumerate(train_loader):\n",
    "        imgs = imgs.to(DEVICE).float()\n",
    "        masks = masks.to(DEVICE)\n",
    "\n",
    "        preds = model(imgs)\n",
    "        loss_value = loss(preds, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss_value.item()\n",
    "        \n",
    "        for k in range(2):\n",
    "            plt.figure(figsize=(9,3))\n",
    "\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.title(\"Imagem Original\")\n",
    "            plt.imshow(imgs[k].cpu()[0], cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.title(\"Weak Label inicial\")\n",
    "            plt.imshow(masks[k].cpu()[0], cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            plt.subplot(1,3,3)\n",
    "            plt.title(\"Weak Label Gerada\")\n",
    "            plt.imshow(preds[k].detach().cpu()[0], cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
