{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation-models-pytorch\n",
      "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (2.0.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (11.3.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.7.0)\n",
      "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (1.0.22)\n",
      "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.24.0+cu126)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.11.12)\n",
      "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: segmentation-models-pytorch\n",
      "Successfully installed segmentation-models-pytorch-0.5.0\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.22)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.0+cu126)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install segmentation-models-pytorch\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-04T20:10:02.206879Z",
     "iopub.status.busy": "2025-12-04T20:10:02.206582Z",
     "iopub.status.idle": "2025-12-04T20:10:02.412655Z",
     "shell.execute_reply": "2025-12-04T20:10:02.411859Z",
     "shell.execute_reply.started": "2025-12-04T20:10:02.206849Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.io import decode_image\n",
    "from torchvision.io.image import ImageReadMode\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from skimage import morphology, measure\n",
    "\n",
    "DEVICE = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o caminho do dataset de input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:10:02.413761Z",
     "iopub.status.busy": "2025-12-04T20:10:02.413516Z",
     "iopub.status.idle": "2025-12-04T20:10:02.418634Z",
     "shell.execute_reply": "2025-12-04T20:10:02.417759Z",
     "shell.execute_reply.started": "2025-12-04T20:10:02.413735Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'chest-xray-pneumonia' dataset.\n"
     ]
    }
   ],
   "source": [
    "#### SE FOR RODAR NO KAGGLE\n",
    "# INPUT_DIR = \"/kaggle/input/chest-xray-pneumonia/chest_xray/\"\n",
    "#### SE QUISER RODAR LOCAL OU NO COLAB\n",
    "INPUT_DIR = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "INPUT_DIR += \"/chest_xray/\"\n",
    "# OUTPUT_DIR = \"/kaggle/working/weak_masks\"\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição das funções que geram as weak labels e que calculam o QC (Quality Control)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:10:22.761950Z",
     "iopub.status.busy": "2025-12-04T20:10:22.761385Z",
     "iopub.status.idle": "2025-12-04T20:10:22.772302Z",
     "shell.execute_reply": "2025-12-04T20:10:22.771609Z",
     "shell.execute_reply.started": "2025-12-04T20:10:22.761925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_weak_mask(img_path):\n",
    "    # Carrega a imagem e redimenciona\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    h, w = img.shape\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    # \"Estoura\" pixels extremos para que não entrem na máscara\n",
    "    img[img < 50] = 255 \n",
    "    img[img > 180] = 255\n",
    "    \n",
    "    # Equalização + suavização\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    I = clahe.apply(img)\n",
    "    I = cv2.GaussianBlur(I, (7,7), 0)\n",
    "    \n",
    "    for ang in np.arange(0, 151, 30):\n",
    "        se = np.zeros((15, 15), np.uint8)\n",
    "        cv2.ellipse(se, (15//2, 15//2), (15//2, 1), ang, 0, 360, 1, -1)\n",
    "        I_supp = cv2.morphologyEx(I, cv2.MORPH_OPEN, se)\n",
    "        I = cv2.min(I, I_supp)\n",
    "        \n",
    "    # Inverte para que opacidades fiquem claras\n",
    "    I_inv = cv2.normalize(255 - I, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Filtro bilateral\n",
    "    I_inv_bilateral = cv2.bilateralFilter(I_inv.astype(np.uint8), d=-1, sigmaColor=0.25*255, sigmaSpace=15)\n",
    "\n",
    "    # Aplica um treshold simples\n",
    "    _, bw = cv2.threshold(I_inv_bilateral, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Limpa regiões fora dos pulmões\n",
    "    # remove um pequeno pedaço do topo e das laterais que não incluem o pulmão (geralmente)\n",
    "    bw[:40, :], bw[:, -70:], bw[:, :70] = 0,0, 0\n",
    "    \n",
    "    # Morfologia para suavizar\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
    "    bw = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel)\n",
    "    bw = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Mantém regiões internas\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(bw)\n",
    "    mask_out = np.zeros_like(bw)\n",
    "    \n",
    "    for i in range(1, num_labels):\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        x,y = stats[i, cv2.CC_STAT_LEFT], stats[i, cv2.CC_STAT_TOP]\n",
    "        wc,hc = stats[i, cv2.CC_STAT_WIDTH], stats[i, cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "        # Descarta regiões no topo e muito pequenas\n",
    "        if area > 500 and y > 39:\n",
    "            mask_out[labels == i] = 255\n",
    "\n",
    "    # Remove objetos pequenos (geralmente ombro ou parte da silhueta lateral)\n",
    "    mask_out = morphology.remove_small_objects(mask_out.astype(bool), min_size=5000)\n",
    "    \n",
    "    # Volta ao tamanho original\n",
    "    mask_out = mask_out.astype(np.uint8)\n",
    "    mask_out = cv2.resize(mask_out, (w, h))\n",
    "    \n",
    "    return torch.from_numpy(mask_out).unsqueeze(0).float()\n",
    "\n",
    "# Função QC\n",
    "def qc_score(mask, min_area=0.04, max_area=0.3, min_ecc=0.4, max_ecc=0.98, max_aspect=0.35, num_obj=2):\n",
    "    props = measure.regionprops(measure.label(mask[0]))\n",
    "    # Apenas os 2 maiores objetos (idealmente apenas pulmões)\n",
    "    props = sorted(props, key=lambda x: x.area, reverse=True)[:2]\n",
    "\n",
    "    H, W = mask[0].shape\n",
    "\n",
    "    scores = 0\n",
    "\n",
    "    try:\n",
    "        biggest_area = props[0].area\n",
    "    except:\n",
    "        print(f\"Mascara problemática, Nº de objetos nela: {len(props)}\")\n",
    "        return 0\n",
    "\n",
    "    for p in props:\n",
    "        lung_scores = list()\n",
    "        # Área relativa\n",
    "        area_frac = p.area / (H * W)\n",
    "        if area_frac < min_area:\n",
    "            lung_scores.append(area_frac / min_area)\n",
    "        elif area_frac > max_area:\n",
    "            lung_scores.append(max_area / area_frac)\n",
    "        else:\n",
    "            lung_scores.append(1.0)\n",
    "\n",
    "        # Eccentricidade\n",
    "        ecc = p.eccentricity\n",
    "        if ecc < min_ecc:\n",
    "            lung_scores.append(ecc / min_ecc)\n",
    "        elif ecc > max_ecc:\n",
    "            lung_scores.append(max_ecc / ecc)\n",
    "        else:\n",
    "            lung_scores.append(1.0)\n",
    "\n",
    "        # Solidity\n",
    "        lung_scores.append(p.solidity)\n",
    "\n",
    "        # Extent\n",
    "        lung_scores.append(p.extent)\n",
    "\n",
    "        # Aspect ratio\n",
    "        minr, minc, maxr, maxc = p.bbox\n",
    "        bbox_h = maxr - minr\n",
    "        bbox_w = maxc - minc\n",
    "        aspect = max(bbox_h / (bbox_w + 1e-9), bbox_w / (bbox_h + 1e-9))\n",
    "        if aspect > max_aspect:\n",
    "            lung_scores.append(max_aspect / aspect)\n",
    "        else:\n",
    "            lung_scores.append(1.0)\n",
    "\n",
    "        # Nº de objetos\n",
    "        n_obj = len(props)\n",
    "        if n_obj > num_obj:\n",
    "            lung_scores.append(1 / n_obj)\n",
    "        else:\n",
    "            lung_scores.append(n_obj / num_obj)\n",
    "       \n",
    "        # Soma o score do pulmão ao score final ponderado pela diferença de tamanho entre pulmões \n",
    "        scores += np.mean(lung_scores) * (p.area / biggest_area)\n",
    "\n",
    "    return scores / 2 # Média dos pulmões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe de Dataset e Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfSegCXRDataset(Dataset):\n",
    "    def __init__(self, dataset_path=INPUT_DIR, image_size=None, augment=None, device=DEVICE):\n",
    "        self._path_data = dataset_path\n",
    "        val_paths  = glob(os.path.join(self._path_data, \"val\", \"**\", \"*.jpeg\"), recursive=True)\n",
    "        test_paths = glob(os.path.join(self._path_data, \"test\", \"**\", \"*.jpeg\"), recursive=True)\n",
    "        self.data_paths = val_paths + test_paths\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        if image_size:\n",
    "            self.resize_image = v2.Resize(size=image_size, interpolation=v2.InterpolationMode.BILINEAR, antialias=True)\n",
    "            self.resize_mask = v2.Resize(size=image_size, interpolation=v2.InterpolationMode.NEAREST)\n",
    "        else:\n",
    "            self.resize_image = lambda x: x\n",
    "            self.resize_mask = lambda x: x\n",
    "\n",
    "        self.augment = augment if augment else lambda x, y: (x, y)\n",
    "\n",
    "        self.data = list()\n",
    "        \n",
    "        for index in range(len(self.data_paths)):\n",
    "            image_path = self.data_paths[index]\n",
    "\n",
    "            image = decode_image(image_path, mode=ImageReadMode.GRAY).to(self.device)\n",
    "            mask = generate_weak_mask(image_path)\n",
    "    \n",
    "    \n",
    "            image = self.resize_image(image)\n",
    "            mask = self.resize_mask(mask)\n",
    "\n",
    "            self.data.append([image, mask])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, mask = self.data[index]\n",
    "        \n",
    "        qc = qc_score(mask)\n",
    "        \n",
    "        image, mask = self.augment(image, mask)\n",
    "\n",
    "        return image, mask, qc\n",
    "    \n",
    "class CXRAugmentation:\n",
    "    def __init__(self, flip_prob=0.5, rotate_prob=0.5, translade_prob=0.5, change_quality_prob=0.3):\n",
    "        self._flip_prob = flip_prob\n",
    "        self._rotate_prob = rotate_prob\n",
    "        self._apply_prob = change_quality_prob\n",
    "        self._translade_prob = translade_prob\n",
    "\n",
    "    def apply(self, image, mask):\n",
    "        augment_list = list()\n",
    "\n",
    "        if np.random.rand() < self._flip_prob:\n",
    "            augment_list.append(lambda img, msk: (TF.hflip(img), TF.hflip(msk)))\n",
    "\n",
    "        if np.random.rand() < self._translade_prob + 1:\n",
    "            prop_x = float(np.random.choice(np.arange(-5, 5.5, 0.5))) / 100\n",
    "            prop_y = float(np.random.choice(np.arange(-5, 5.5, 0.5))) / 100\n",
    "\n",
    "            H, W = image[0].shape\n",
    "            translate_props = (int(prop_x * W), int(prop_y * H))\n",
    "\n",
    "            augment_list.append(lambda img, msk: (TF.affine(img, 0, translate_props, 1, (0, 0)), TF.affine(msk, 0, translate_props, 1, (0, 0))))\n",
    "\n",
    "        if np.random.rand() < self._rotate_prob:\n",
    "            angle = int(np.random.choice(np.arange(-5, 6)))\n",
    "            augment_list.append(lambda img, msk: (TF.rotate(img, angle), TF.rotate(msk, angle)))\n",
    "\n",
    "\n",
    "        if len(augment_list) < 1:\n",
    "            augment_list.append(lambda x, y: (x, y))\n",
    "\n",
    "        image, mask = v2.Compose(augment_list)(image, mask)\n",
    "\n",
    "        image = v2.RandomApply([\n",
    "            v2.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            v2.GaussianBlur(kernel_size=3)\n",
    "        ], p=self._apply_prob)(image)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        return self.apply(image, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para fazer o split do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(dataset, test_prop=0.2):\n",
    "    n_features = len(dataset)\n",
    "\n",
    "    test_size = round(n_features * test_prop)\n",
    "    train_size = n_features - test_size\n",
    "\n",
    "    return random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pequeno teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T20:28:18.652746Z",
     "iopub.status.busy": "2025-12-04T20:28:18.652056Z",
     "iopub.status.idle": "2025-12-04T20:28:19.214697Z",
     "shell.execute_reply": "2025-12-04T20:28:19.213866Z",
     "shell.execute_reply.started": "2025-12-04T20:28:18.652718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATASET = SelfSegCXRDataset(image_size=(512, 512), augment=CXRAugmentation())\n",
    "\n",
    "train_ds, test_ds = get_train_test_split(DATASET)\n",
    "\n",
    "for i in range(5):\n",
    "    img, mask, qc = train_ds[i]\n",
    "\n",
    "    img, mask = img.cpu()[0], mask.cpu()[0]\n",
    "    \n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Imagem Original\")\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Imagem e Máscara sobrepostas\")\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    masked_overlay = np.ma.masked_where(mask == 0, mask)\n",
    "    plt.imshow(masked_overlay, cmap = \"spring\", alpha = 0.3)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Weak Label Gerada\")\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    print(f\"QC_{i+1} = {qc}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSoftDiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(WeightedSoftDiceLoss, self).__init__()\n",
    "        self._smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets, weights=None):\n",
    "        \"\"\"\n",
    "        preds: tensor [B,1,H,W] com probabilidades\n",
    "        targets: tensor [B,1,H,W] com ground truth binário\n",
    "        weights: tensor [B] com pesos por amostra\n",
    "        \"\"\"\n",
    "        B = preds.shape[0]\n",
    "        losses = []\n",
    "        for i in range(B):\n",
    "            p = preds[i].view(-1)\n",
    "            g = targets[i].view(-1)\n",
    "\n",
    "            intersection = torch.sum(p * g)\n",
    "            dice = (2. * intersection + self._smooth) / (torch.sum(p) + torch.sum(g) + self._smooth)\n",
    "            loss = 1 - dice\n",
    "\n",
    "            if weights is not None:\n",
    "                loss = loss * weights[i]\n",
    "\n",
    "            losses.append(loss)\n",
    "\n",
    "        losses = torch.stack(losses)\n",
    "\n",
    "        if weights is not None:\n",
    "            return torch.sum(losses) / (torch.sum(weights) + self._smooth)\n",
    "        else:\n",
    "            return torch.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unet(model, train_loader, loss, optimizer, num_epochs=5,\n",
    "               use_weights=False, device=DEVICE, save_path=None):\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_state = None\n",
    "\n",
    "    history_loss = list()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "\n",
    "        # print(f\"\\nIniciando época {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # tqdm\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        \n",
    "        for imgs, masks, qc in progress_bar:\n",
    "            imgs = imgs.to(device).float()\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # QC opcional como pesos\n",
    "            if use_weights:\n",
    "                weights = qc.to(device).float()\n",
    "            else:\n",
    "                weights = None\n",
    "\n",
    "            preds = model(imgs)\n",
    "            # loss_value = loss(preds, masks, weights=weights)\n",
    "            loss_value = loss(preds, masks)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total += loss_value.item()\n",
    "\n",
    "            # Atualiza barra com a loss atual\n",
    "            progress_bar.set_postfix(loss=loss_value.item())\n",
    "\n",
    "        epoch_loss = total / len(train_loader)\n",
    "        print(f\"Loss médio da época {epoch + 1}: {epoch_loss:.4f}\")\n",
    "        history_loss.append(epoch_loss)\n",
    "        # Melhor chackpoint\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_state = model.state_dict()\n",
    "            # print(f\"Novo melhor modelo! Loss = {best_loss:.4f}\")\n",
    "\n",
    "    # Salva modelo\n",
    "    if save_path is not None and best_state is not None:\n",
    "        torch.save(best_state, save_path)\n",
    "        print(f\"Modelo salvo (best checkpoint) em: {save_path}\")\n",
    "\n",
    "    return model, history_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qc_filter(dataset, threshold):\n",
    "    filtered = list()\n",
    "    for img, mask, qc in dataset:\n",
    "        if qc > threshold:\n",
    "            filtered.append((img, mask, qc))\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Learning com as weak masks\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    "    activation=\"sigmoid\"\n",
    ")\n",
    "\n",
    "loss = smp.losses.DiceLoss(mode=\"binary\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_dataset, val_dataset = get_train_test_split(DATASET)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "threshold = 0.7\n",
    "MAX_SELF_LEARNING_CYCLE = 5\n",
    "MIN_DATA = len(DATASET) // 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered = qc_filter(train_dataset, threshold)\n",
    "train_loader_loop = DataLoader(train_filtered, batch_size=16, shuffle=True)\n",
    "\n",
    "model, loss_1 = train_unet(\n",
    "    model,\n",
    "    train_loader_loop,\n",
    "    loss,\n",
    "    optimizer,\n",
    "    num_epochs=5,\n",
    "    use_weights=False  \n",
    ")\n",
    "\n",
    "for i in range(MAX_SELF_LEARNING_CYCLE):\n",
    "    print(f\"iteração nº{i+1}\")\n",
    "    model.eval()\n",
    "    new_train_data = list()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, mask, qc in tqdm(train_dataset, desc=\"Previsões\"):\n",
    "            img = img.unsqueeze(0).to(DEVICE).float()\n",
    "\n",
    "            pred = model(img)[0].cpu()\n",
    "            \n",
    "            pred_mask = (pred > 0.5).float()\n",
    "\n",
    "            qc_pred = qc_score(pred_mask)\n",
    "\n",
    "            if qc_pred > threshold:\n",
    "                new_train_data.append((img.cpu().squeeze(0), pred_mask.unsqueeze(0), qc_pred))\n",
    "\n",
    "    print(f\"Quantidade de mascaras aprovadas pelo QC: {len(new_train_data)}\")\n",
    "    \n",
    "    train_loader_loop = DataLoader(new_train_data, batch_size=16, shuffle=True)\n",
    "\n",
    "    # Re-treina a rede\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    model, loss_sl = train_unet(model, train_loader_loop, loss, optimizer)\n",
    "\n",
    "    # Avaliação no conjunto de validação\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, qc in val_loader:\n",
    "            imgs, masks = imgs.to(DEVICE).float(), masks.to(DEVICE)\n",
    "            preds = model(imgs)\n",
    "            val_loss += loss(preds, masks).item()\n",
    "\n",
    "    print(f\"Loss médio na validação: {val_loss / len(val_loader):.4f}\")\n",
    "\n",
    "    if len(new_train_data) > MIN_DATA:\n",
    "        print(\"Parando\")\n",
    "        break\n",
    "\n",
    "torch.save(model.state_dict(), \"self_learning_unet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_1)\n",
    "plt.plot(loss_sl)\n",
    "plt.plot(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_set = new_train_data\n",
    "final_train_loader = DataLoader(final_train_set, batch_size=16, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "final_model, loss_final = train_unet(model, final_train_loader, loss, optimizer, num_epochs=3)\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for imgs, masks, qc in val_loader:\n",
    "        imgs, masks = imgs.to(DEVICE).float(), masks.to(DEVICE)\n",
    "        preds = final_model(imgs)\n",
    "        val_loss += loss(preds, masks).item()\n",
    "        if i%10 == 0:\n",
    "            for j in range(2):\n",
    "                img, mask = imgs[j].cpu()[0], preds[j].cpu()[0]\n",
    "            \n",
    "                plt.figure(figsize=(18,6))\n",
    "                plt.subplot(1,3,1)\n",
    "                plt.title(\"Imagem Original\")\n",
    "                plt.imshow(img, cmap=\"gray\")\n",
    "                plt.axis(\"off\")\n",
    "            \n",
    "                plt.subplot(1,3,2)\n",
    "                plt.title(\"Imagem e Máscara sobrepostas\")\n",
    "                plt.imshow(img, cmap=\"gray\")\n",
    "                masked_overlay = np.ma.masked_where(mask == 0, mask)\n",
    "                plt.imshow(masked_overlay, cmap = \"spring\", alpha = 0.3)\n",
    "                plt.axis(\"off\")\n",
    "                \n",
    "                plt.subplot(1,3,3)\n",
    "                plt.title(\"Weak Label Gerada\")\n",
    "                plt.imshow(mask, cmap=\"gray\")\n",
    "                plt.axis(\"off\")\n",
    "            \n",
    "                print(f\"QC_{i+1} = {qc[j]}\")\n",
    "                \n",
    "                plt.show()\n",
    "            \n",
    "print(f\"Loss médio na validação: {val_loss / len(val_loader):.4f}\")\n",
    "\n",
    "torch.save(final_model.state_dict(), \"final_unet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_final)\n",
    "plt.plot(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simples de 20 mascaras aleatórias\n",
    "\n",
    "random_choice_indexes = np.random.choice(range(len(new_train_data)), 20)\n",
    "\n",
    "for img, mask, qc in new_train_data[random_choice_indexes]:\n",
    "    img, mask = img.cpu()[0], mask.cpu()[0][0]\n",
    "    \n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Imagem Original\")\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Imagem e Máscara sobrepostas\")\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    masked_overlay = np.ma.masked_where(mask == 0, mask)\n",
    "    plt.imshow(masked_overlay, cmap = \"spring\", alpha = 0.3)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Weak Label Gerada\")\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    print(f\"QC_{i+1} = {qc}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
