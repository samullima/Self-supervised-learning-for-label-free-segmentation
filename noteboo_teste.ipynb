{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation-models-pytorch\n!pip install timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:59:22.409790Z","iopub.execute_input":"2025-12-08T15:59:22.410605Z","iopub.status.idle":"2025-12-08T15:59:29.536515Z","shell.execute_reply.started":"2025-12-08T15:59:22.410580Z","shell.execute_reply":"2025-12-08T15:59:29.535723Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.11/dist-packages (0.5.0)\nRequirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.36.0)\nRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.26.4)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (11.3.0)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.5.3)\nRequirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.0.19)\nRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation-models-pytorch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.3->segmentation-models-pytorch) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.10.5)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.19)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.36.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.2.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->timm) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->timm) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->timm) (2024.2.0)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Part 1/6 - imports e utilitários\nimport os\nimport cv2\nimport numpy as np\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport segmentation_models_pytorch as smp\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef decode_image(path, to_gray=True):\n    \"\"\"\n    Carrega imagem com cv2 e retorna tensor torch float32 shape [1, H, W] (scale 0..1).\n    - Se imagem já é grayscale, retorna canal único.\n    - Se color, converte para gray (pulmão tipicamente gray).\n    \"\"\"\n    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n    if img is None:\n        raise FileNotFoundError(f\"Image not found: {path}\")\n\n    # Se alpha presente, descarta\n    if img.ndim == 3 and img.shape[2] == 4:\n        img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n\n    if to_gray:\n        if img.ndim == 3:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    else:\n        # manter color se necessário (não usado aqui)\n        if img.ndim == 2:\n            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n\n    # garantir uint8\n    if img.dtype != np.uint8:\n        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n\n    # converter para tensor [1,H,W]\n    img = img.astype(np.float32) / 255.0\n    img = np.expand_dims(img, axis=0)  # 1,H,W\n    return torch.from_numpy(img)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:59:29.538507Z","iopub.execute_input":"2025-12-08T15:59:29.538777Z","iopub.status.idle":"2025-12-08T15:59:29.548402Z","shell.execute_reply.started":"2025-12-08T15:59:29.538751Z","shell.execute_reply":"2025-12-08T15:59:29.547504Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Para geração de weak masks\ndef generate_weak_mask_cxr(img_path, out_size=None):\n    orig = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    if orig is None:\n        raise FileNotFoundError(img_path)\n    h_orig, w_orig = orig.shape\n\n    # 1. Trabalhar em 512\n    I = cv2.resize(orig, (512,512), interpolation=cv2.INTER_AREA)\n\n    # 2. CLAHE + blur leve\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    I = clahe.apply(I)\n    I = cv2.GaussianBlur(I, (7,7), 0)\n\n    # 3. Top-hat: reduzir agressividade\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(21,21))\n    toph = cv2.morphologyEx(I, cv2.MORPH_TOPHAT, kernel)\n\n    # Mistura com original para não perder anatomia\n    I2 = cv2.addWeighted(I, 0.7, toph, 0.3, 0)\n\n    # 4. Threshold adaptativo mais realista\n    bw = cv2.adaptiveThreshold(\n        I2, 255,\n        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n        cv2.THRESH_BINARY_INV,\n        31, 5\n    )\n\n    # 5. Remover bordas\n    H, W = bw.shape\n    bw[:int(0.03*H), :] = 0\n    bw[:, :int(0.03*W)] = 0\n    bw[:, -int(0.03*W):] = 0\n\n    # 6. Fechar buracos + suavizar\n    kernel2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(15,15))\n    bw = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel2)\n    bw = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel2)\n\n    # 7. Componentes conectados\n    num, labels, stats, centroids = cv2.connectedComponentsWithStats(bw, 8)\n\n    # manter todos componentes maiores que 1000 px\n    mask_out = np.zeros_like(bw)\n    for i in range(1, num):\n        area = stats[i, cv2.CC_STAT_AREA]\n        if area > 1000:\n            mask_out[labels == i] = 255\n\n    # 8. resize final\n    if out_size is None:\n        mask_final = cv2.resize(mask_out, (w_orig, h_orig), interpolation=cv2.INTER_NEAREST)\n    else:\n        mask_final = cv2.resize(mask_out, (out_size[1], out_size[0]), interpolation=cv2.INTER_NEAREST)\n\n    return mask_final\n\n# função QC\ndef qc_mask(mask,\n            min_area_ratio=0.003,   # 0.3% — antes era 2% (!)\n            max_area_ratio=0.45,    # reduzido para evitar segmentações gigantes\n            min_comp_area=300,      # antes 500 — relaxado\n            expected_comps=1):      # aceitar 1 ou mais componentes\n    if mask is None:\n        return False\n\n    mask_bin = (mask > 127).astype(np.uint8)\n    H, W = mask_bin.shape\n    total = H * W\n\n    if mask_bin.sum() == 0:\n        return False\n\n    # área global\n    area_ratio = mask_bin.sum() / total\n    if not (min_area_ratio <= area_ratio <= max_area_ratio):\n        return False\n\n    # componentes\n    num, labels, stats, _ = cv2.connectedComponentsWithStats(mask_bin, 8)\n    if num <= 1:\n        return False\n\n    # verificar se ao menos 1 componente é relevante\n    areas = stats[1:, cv2.CC_STAT_AREA]\n    if np.max(areas) < min_comp_area:\n        return False\n\n    return True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:59:29.549286Z","iopub.execute_input":"2025-12-08T15:59:29.549562Z","iopub.status.idle":"2025-12-08T15:59:29.577702Z","shell.execute_reply.started":"2025-12-08T15:59:29.549544Z","shell.execute_reply":"2025-12-08T15:59:29.576930Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Datasets\nclass SelfSegDatasetQC(Dataset):\n    \"\"\"\n    Dataset que gera weak masks e aplica QC. Somente arquivos que passam no QC são mantidos.\n    Retorna: img_tensor [1,H,W], mask_tensor [1,H,W], image_path (str)\n    \"\"\"\n    def __init__(self, dataset_path, image_size=(256,256), exts=(\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.bmp\")):\n        files = []\n        for e in exts:\n            files += glob(os.path.join(dataset_path, \"**\", e), recursive=True)\n        files = sorted(files)\n\n        self.image_size = image_size\n        self.valid_files = []\n\n        print(\"Gerando weak masks e aplicando QC (isso pode demorar)...\")\n        for f in tqdm(files):\n            try:\n                mask = generate_weak_mask_cxr(f, out_size=image_size)\n                if qc_mask(mask):\n                    self.valid_files.append((f, mask))\n            except Exception as e:\n                # ignora arquivos problemáticos\n                continue\n\n        print(f\"Arquivos totais: {len(files)}  ->  Válidos após QC: {len(self.valid_files)}\")\n\n    def __len__(self):\n        return len(self.valid_files)\n\n    def __getitem__(self, idx):\n        img_path, mask_np = self.valid_files[idx]\n        # carrega imagem e coloca no tamanho correto\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (self.image_size[1], self.image_size[0]), interpolation=cv2.INTER_AREA)\n        img = img.astype(np.float32)/255.0\n        img = np.expand_dims(img, axis=0)  # 1,H,W\n        img_t = torch.from_numpy(img).float()\n\n        # mask_np já está no tamanho correto porque geramos com out_size em init\n        mask = (mask_np > 127).astype(np.float32)\n        mask = np.expand_dims(mask, axis=0)\n        mask_t = torch.from_numpy(mask).float()\n\n        return img_t, mask_t, img_path\n\n\nclass SelfLearningDataset(Dataset):\n    \"\"\"\n    Dataset que combina imagens originais com pseudo-masks (geradas).\n    Só carrega pares onde a pseudo-mask existe E passa no QC.\n    \"\"\"\n    def __init__(self, img_dir, mask_dir, image_size=(256,256), exts=(\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.bmp\")):\n        files = []\n        for e in exts:\n            files += glob(os.path.join(img_dir, \"**\", e), recursive=True)\n        files = sorted(files)\n\n        self.image_size = image_size\n        self.pairs = []\n\n        print(\"Construindo dataset de self-learning (aplicando QC nas pseudo-masks)...\")\n        for f in tqdm(files):\n            fname = os.path.basename(f)\n            mask_path = os.path.join(mask_dir, fname)\n            if not os.path.exists(mask_path):\n                continue\n            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n            if mask is None:\n                continue\n            # redimensiona máscara para image_size para QC consistente\n            mask_rs = cv2.resize(mask, (image_size[1], image_size[0]), interpolation=cv2.INTER_NEAREST)\n            if qc_mask(mask_rs):\n                self.pairs.append((f, mask_path))\n        print(f\"Imagens com pseudo-masks válidas: {len(self.pairs)}\")\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        img_path, mask_path = self.pairs[idx]\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (self.image_size[1], self.image_size[0]), interpolation=cv2.INTER_AREA)\n        img = img.astype(np.float32)/255.0\n        img = np.expand_dims(img, axis=0)\n        img_t = torch.from_numpy(img).float()\n\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        mask = cv2.resize(mask, (self.image_size[1], self.image_size[0]), interpolation=cv2.INTER_NEAREST)\n        mask = (mask > 127).astype(np.float32)\n        mask = np.expand_dims(mask, axis=0)\n        mask_t = torch.from_numpy(mask).float()\n\n        return img_t, mask_t, img_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:59:29.578571Z","iopub.execute_input":"2025-12-08T15:59:29.578837Z","iopub.status.idle":"2025-12-08T15:59:29.599234Z","shell.execute_reply.started":"2025-12-08T15:59:29.578816Z","shell.execute_reply":"2025-12-08T15:59:29.598337Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Loss combinada \nclass DiceBCELoss(nn.Module):\n    def __init__(self, bce_weight=1.0, dice_weight=1.0, smooth=1e-5):\n        super().__init__()\n        self.bce = nn.BCEWithLogitsLoss()\n        self.bce_w = bce_weight\n        self.dice_w = dice_weight\n        self.smooth = smooth\n\n    def forward(self, logits, target):\n        # logits: [B,1,H,W], target: [B,1,H,W] float 0..1\n        bce = self.bce(logits, target)\n        pred = torch.sigmoid(logits)\n        inter = (pred * target).sum(dim=(2,3))\n        denom = pred.sum(dim=(2,3)) + target.sum(dim=(2,3))\n        dice = (2*inter + self.smooth) / (denom + self.smooth)\n        dice_loss = 1 - dice.mean()\n        return self.bce_w * bce + self.dice_w * dice_loss\n\n# Criação do modelo\ndef create_model(encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=1, classes=1):\n    model = smp.Unet(\n        encoder_name=encoder_name,\n        encoder_weights=encoder_weights,\n        in_channels=in_channels,\n        classes=classes,\n        activation=None\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:59:29.601396Z","iopub.execute_input":"2025-12-08T15:59:29.601635Z","iopub.status.idle":"2025-12-08T15:59:29.621586Z","shell.execute_reply.started":"2025-12-08T15:59:29.601618Z","shell.execute_reply":"2025-12-08T15:59:29.620948Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Training loops e geração de pseudo-labels com QC\n\nfrom torchvision.utils import save_image\n\ndef train_epoch(model, loader, optimizer, loss_fn):\n    model.train()\n    total_loss = 0.0\n    n = 0\n    for imgs, masks, _ in loader:\n        imgs = imgs.to(device)\n        masks = masks.to(device)\n\n        optimizer.zero_grad()\n        preds = model(imgs)\n        loss = loss_fn(preds, masks)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        n += 1\n    return total_loss / (n if n>0 else 1)\n\ndef early_learning(model, dataset, lr=1e-4, epochs=5, batch=8, save_path=None):\n    loader = DataLoader(dataset, batch_size=batch, shuffle=True, num_workers=2, pin_memory=True)\n    model = model.to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    criterion = DiceBCELoss()\n\n    for ep in range(epochs):\n        loss = train_epoch(model, loader, optimizer, criterion)\n        print(f\"[Early Learning] Epoch {ep+1}/{epochs}  loss={loss:.4f}\")\n        if save_path:\n            torch.save(model.state_dict(), f\"{save_path}_early_ep{ep+1}.pth\")\n    return model\n\ndef generate_pseudo_labels(model, dataset_files, out_dir, threshold=0.5, qc_on_save=True):\n    \"\"\"\n    dataset_files: lista de tuples ou caminhos. Para simplicidade, pode passar o dataset que itera em (img, mask, path)\n    Se passar um Dataset (ex: SelfSegDatasetQC), a função itera sobre arquivos originais.\n    \"\"\"\n    os.makedirs(out_dir, exist_ok=True)\n    model.eval()\n    model = model.to(device)\n\n    # construir loader de avaliação que retorna caminhos\n    loader = DataLoader(dataset_files, batch_size=1, shuffle=False)\n\n    saved = 0\n    skipped = 0\n    with torch.no_grad():\n        for imgs, _, img_paths in tqdm(loader, desc=\"Gerando pseudo-labels\"):\n            # imgs: [1,1,H,W], img_paths: tuple/list com path\n            imgs = imgs.to(device)\n            logits = model(imgs)\n            probs = torch.sigmoid(logits)\n            mask_np = (probs.cpu().numpy()[0,0] > threshold).astype(np.uint8) * 255\n\n            fname = os.path.basename(img_paths[0])\n            out_path = os.path.join(out_dir, fname)\n\n            # opcionalmente aplicar QC antes de salvar\n            if qc_on_save:\n                # resize para QC usando same size do loader (imgs)\n                H, W = mask_np.shape\n                if not qc_mask((mask_np).astype(np.uint8)):\n                    skipped += 1\n                    # podemos salvar em um diretório de rejeitados se quisermos\n                    continue\n\n            cv2.imwrite(out_path, mask_np)\n            saved += 1\n    print(f\"Pseudo masks salvas: {saved}  |  puladas (fail QC): {skipped}\")\n\n\ndef self_learning(model, dataset, lr=1e-4, epochs=5, batch=8, save_path=None):\n    loader = DataLoader(dataset, batch_size=batch, shuffle=True, num_workers=2, pin_memory=True)\n    model = model.to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    criterion = DiceBCELoss()\n\n    for ep in range(epochs):\n        loss = train_epoch(model, loader, optimizer, criterion)\n        print(f\"[Self Learning] Epoch {ep+1}/{epochs}  loss={loss:.4f}\")\n        if save_path:\n            torch.save(model.state_dict(), f\"{save_path}_self_ep{ep+1}.pth\")\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:59:29.622306Z","iopub.execute_input":"2025-12-08T15:59:29.622499Z","iopub.status.idle":"2025-12-08T15:59:29.651689Z","shell.execute_reply.started":"2025-12-08T15:59:29.622483Z","shell.execute_reply":"2025-12-08T15:59:29.650757Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Pipeline\n\nINPUT_DIR = \"/kaggle/input/chest-xray-pneumonia/chest_xray/test/NORMAL\"   \nOUT_ROOT = \"/kaggle/working/weak_masks\"\nPSEUDO_DIR = os.path.join(OUT_ROOT, \"pseudo_masks\")\nPSEUDO_ROUND2 = os.path.join(OUT_ROOT, \"pseudo_masks_round2\")\nMODEL_SAVE = \"/kaggle/working/unet_model\"\n\nimage_size = (256,256)\n\n# 1) Gerar weak dataset com QC \nweak_dataset = SelfSegDatasetQC(INPUT_DIR, image_size=image_size)\n\n# 2) Early learning (treina usando as weak masks aprovadas)\nmodel = create_model()\nmodel = early_learning(model, weak_dataset, lr=1e-4, epochs=5, batch=8, save_path=MODEL_SAVE)\n\n# 3) Gerar pseudo-labels (round1) em PSEUDO_DIR. OBS: a função aplica QC antes de salvar\ngenerate_pseudo_labels(model, weak_dataset, PSEUDO_DIR, threshold=0.5, qc_on_save=True)\n\n# 4) Construir dataset de self-learning usando apenas pseudo-masks válidas\npseudo_dataset = SelfLearningDataset(INPUT_DIR, PSEUDO_DIR, image_size=image_size)\n\n# 5) Self-learning (treina com pseudo-masks filtradas)\nmodel = self_learning(model, pseudo_dataset, lr=1e-4, epochs=5, batch=8, save_path=MODEL_SAVE)\n\n# 6) Gerar pseudo-labels round2 \n# Recriar um loader/dataset para evitar confusão. OBS: podemos usar pseudo_dataset (que itera imagens válidas)\ngenerate_pseudo_labels(model, pseudo_dataset, PSEUDO_ROUND2, threshold=0.5, qc_on_save=True)\n\n# Ideia: depois podemos treinar um modelo final com pseudo_masks_round2 + weak_dataset combinado.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:59:29.652630Z","iopub.execute_input":"2025-12-08T15:59:29.653066Z","iopub.status.idle":"2025-12-08T16:00:07.824898Z","shell.execute_reply.started":"2025-12-08T15:59:29.653038Z","shell.execute_reply":"2025-12-08T16:00:07.823972Z"}},"outputs":[{"name":"stdout","text":"Gerando weak masks e aplicando QC (isso pode demorar)...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [00:06<00:00, 35.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Arquivos totais: 234  ->  Válidos após QC: 131\n[Early Learning] Epoch 1/5  loss=1.1192\n[Early Learning] Epoch 2/5  loss=0.8617\n[Early Learning] Epoch 3/5  loss=0.7486\n[Early Learning] Epoch 4/5  loss=0.6651\n[Early Learning] Epoch 5/5  loss=0.6049\n","output_type":"stream"},{"name":"stderr","text":"Gerando pseudo-labels: 100%|██████████| 131/131 [00:03<00:00, 39.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Pseudo masks salvas: 90  |  puladas (fail QC): 41\nConstruindo dataset de self-learning (aplicando QC nas pseudo-masks)...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [00:00<00:00, 1603.78it/s]","output_type":"stream"},{"name":"stdout","text":"Imagens com pseudo-masks válidas: 115\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"[Self Learning] Epoch 1/5  loss=0.4370\n[Self Learning] Epoch 2/5  loss=0.3761\n[Self Learning] Epoch 3/5  loss=0.3286\n[Self Learning] Epoch 4/5  loss=0.3043\n[Self Learning] Epoch 5/5  loss=0.2742\n","output_type":"stream"},{"name":"stderr","text":"Gerando pseudo-labels: 100%|██████████| 115/115 [00:03<00:00, 35.90it/s]","output_type":"stream"},{"name":"stdout","text":"Pseudo masks salvas: 113  |  puladas (fail QC): 2\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":25}]}